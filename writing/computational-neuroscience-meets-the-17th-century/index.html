<!doctype html>
<html lang="en-us" dir="ltr">
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width" />
    <meta
      name="description"
      content="Do we live in a world of ideas? &#x1f4a1;"
    />
    <meta name="robots" content="index, follow" />
    <meta name="author" content="Steven Hay" />

    <link rel="canonical" href="" />

    <meta
      http-equiv="Content-Security-Policy"
      content="default-src 'self'; script-src 'self' https://stvhay.github.io;"
    />
    <meta name="referrer" content="strict-origin-when-cross-origin" />
    <meta
      http-equiv="Content-Security-Policy"
      content="frame-ancestors 'none';"
    />
    <meta http-equiv="X-Content-Type-Options" content="nosniff" />

    <title>
      Computational Neuroscience Meets the 17th Century | Steven Hay
    </title>
    <link
      rel="stylesheet"
      href="/css/main.min.fd22d10099ece351d9bbe94079ceb9a1d28e37401e91f7159a450fa230b21c37.css"
      integrity="sha256-/SLRAJns41HZu&#43;lAec65odKON0AekfcVmkUPojCyHDc="
      crossorigin="anonymous"
    />
  </head>
  <body>
    <header>
      <h1>Steven Hay</h1>
    </header>
    <nav>
      <a href="/">Home</a>
      <a href="/docs/cv/cv-steve-hay.pdf" target="_blank">CV</a>
      <a href="/portfolio/">Portfolio</a>
      <a href="/writing">Writing</a>
      <a href="/#contact">Contact</a>
    </nav>
    <main>
      <section class="container">
        <div class="article">
          <h1>Computational Neuroscience Meets the 17th Century</h1>
          <time datetime="2025-05-27T15:48:07-04:00">May 27, 2025</time>

          <br />
          <div class="article-img">
            <img
              src="/writing/computational-neuroscience-meets-the-17th-century/img.jpg"
              alt="Computational Neuroscience Meets the 17th Century"
            />
          </div>

          <p><em>Do we live in a world of ideas?</em> &#x1f4a1;</p>
          <p>
            Descartes famously kicked off an era of Western philosophy with
            &ldquo;Cogito, ergo sum&rdquo;—an attempt to establish a basis for
            human existence and knowledge that assumed as little as possible.
            Out of this idea sprung a dualistic theory of mind and body. The
            theory posits that the world is composed of fundamentally two types
            of &lsquo;stuff&rsquo;: stuff that extends into the
            three-dimensional space (matter) and stuff that doesn&rsquo;t
            (ideas). For a long time this idea was popular, but in modern
            circles of philosophy, it has largely gone out of fashion in favor
            of materialism (one &ldquo;thing&rdquo;), which seems more sensible
            nowadays where more hard-nosed empiricism so fundamentally shapes
            our society.
          </p>
          <p>
            In the 17th century, however, things weren&rsquo;t quite as settled.
            Irish philosopher George Berkeley believed the opposite of
            materialism—the world (including all matter) was composed only of
            ideas
            <sup id="fnref:1"
              ><a href="#fn:1" class="footnote-ref" role="doc-noteref"
                >1</a
              ></sup
            >. Like modern materialists, he didn&rsquo;t really understand how
            dualism could make much sense. How does spirit interact with matter
            exactly? My question is:
            <strong
              >does Berkeleyan idealism offer us any relevant perspective when
              we study neuroscience</strong
            >?
          </p>
          <p>
            My line of thinking is inspired by a 2014 paper<sup id="fnref:2"
              ><a href="#fn:2" class="footnote-ref" role="doc-noteref"
                >2</a
              ></sup
            >
            that summarizes the state of neuroscience research on scene
            analysis—the study of how our brain turns information (materialist
            philosophers like the term &ldquo;sense-data&rdquo;) into an
            internal representation of the world. It then argues that scene
            analysis is not only an incredibly hard problem, but that many of
            the modern ways we study this problem fail to address some very
            fundamental questions.
          </p>
          <p>
            It turns out that most empirical research into scene analysis is
            conducted using very simplified forms—lines and basic geometric
            figures on simple backgrounds and neutral lighting. Arguably, this
            makes sense because it provides a controlled experimental
            environment. Unfortunately, while this research framework has given
            us many useful insights, the paper argues that we remain relatively
            stuck on how we map those insights to ecologically relevant scene
            analysis problems that all animals are constantly solving.<sup
              id="fnref:3"
              ><a href="#fn:3" class="footnote-ref" role="doc-noteref"
                >3</a
              ></sup
            >
          </p>
          <p>
            As I was reading, I was thinking about Berkeley&rsquo;s idealism. As
            I learn more about human perception in general, the more I realize
            that our perceptual world is far more like a Star Trek holodeck—<em
              >a constructed reality</em
            >—than some kind of more direct<sup id="fnref:4"
              ><a href="#fn:4" class="footnote-ref" role="doc-noteref"
                >4</a
              ></sup
            >
            perception. Our lived experience is in fact deeply subjective. Not
            only is our brain heavily involved in numerous layers of represental
            transformations when processing sense-data, the resultant real-time
            representational model is informed by a shockingly tiny subset of
            the available information (neurons are expensive!<sup id="fnref:5"
              ><a href="#fn:5" class="footnote-ref" role="doc-noteref"
                >5</a
              ></sup
            >). So, while I don&rsquo;t think the world is
            <em>literally</em> built of ideas, it is not a totally unreasonable
            dialectical approach to how we materialists study perception.
          </p>
          <p>
            As an example, saccades are rapid eye movements that constantly
            shift our gaze. The movements are essential for our ability to
            process visual information because we physically don&rsquo;t have
            the neural bandwidth to take in all of our visual field in without
            heavy compression<sup id="fnref:6"
              ><a href="#fn:6" class="footnote-ref" role="doc-noteref"
                >6</a
              ></sup
            >. Our brain controls where our eyes are pointed based on a mix of
            unconscious neural control systems tracking our head, body, and eye
            position; random saccade and even smaller microsaccade movements, as
            well as high-level task-driven signals that determine our attention.
            All of the high-acuity visual data we get (e.g. detail and color)
            comes via a surprisingly narrow field of view, and the rest we fill
            in with prior knowledge and expectations and much more limited
            peripheral visual data.
          </p>
          <p>
            This motif recurs throughout the perceptive systems of most animals.
            For example, the paper discusses jumping spiders with three pairs of
            different kinds of eyes—only one of the pairs providing detail, and
            provides it as a one-dimensional vertical slit. The spider uses
            these eyes to scan selected areas of its visual field horizontally
            like a crazed dot-matrix
            <a
              href="https://youtu.be/A_vXA058EDY?t=23"
              target="_blank"
              rel="noopener noreferrer"
              >printer</a
            >. Like us, the spider then assembles these samples into a
            three-dimensional representation of the world—the only way to
            explain its complex behaviors.
          </p>
          <p>
            Bats have even more impressive autonomic systems in place to operate
            their neural sonar. Not only do they generate (encode) and process
            (decode) various sophisticated sonar signals, they focus sonic
            energy at targets of interest and actively adjust their sonar
            transmission frequencies away from those of nearby bats to reduce
            signal interference.
          </p>
          <p>
            Meanwhile, some of our most famous computational vision models bear
            little resemblance to these attention-driven biological systems.
            Consider the incredibly successful ResNet image classifier. It reads
            entire images, breaks them down into spatio-temporal chunks, then
            pieces it all back together into increasingly complex groups of
            pixels for grouping and labeling. While there is evidence for
            biological neurons doing spatio-temporal filtering<sup id="fnref:7"
              ><a href="#fn:7" class="footnote-ref" role="doc-noteref"
                >7</a
              ></sup
            >, Resnet has no concept of three-dimensional space other than what
            it has memorized, no opinions on what it should be paying attention
            to. So, while pieces of Resnet bear some resemblance to some parts
            of biological brains, its overall computational architecture
            doesn&rsquo;t really have known traceability back to any biological
            systems. The success of ResNet has much more to do with its
            accomplishments as a technology than how it can specifically explain
            the function of biological neural systems or animal behavior<sup
              id="fnref:8"
              ><a href="#fn:8" class="footnote-ref" role="doc-noteref"
                >8</a
              ></sup
            >—the more fundamental aim of science.
          </p>
          <p>
            Yet scientists have the urge to apply ResNet when searching to
            understand the biological brain because its impressive performance
            might indeed reveal something more fundamental, and because it
            overall architecture resonates with our subjective experience of
            perception. The human vision system makes us feel very connected to
            the world. It feels like our eyes are taking it all in like a camera
            taking pictures or video. Therefore, it seems like the mind might
            process images like ResNet. It is tempting to dismiss the
            unconscious mechanisms of eye movement as boring biological
            engineering details—a distraction from the really interesting stuff
            that makes up human perception and thought—when the opposite (or
            neither!) could be true.
          </p>
          <p>
            So while we are not literally living in Berkeleyan world of ideas,
            the vast bulk of our perceptive reality can be viewed as a somewhat
            Berkeleyan mental construct. Our brain has made us a personal
            holodeck<sup id="fnref:9"
              ><a href="#fn:9" class="footnote-ref" role="doc-noteref"
                >9</a
              ></sup
            >
            very much tuned for evolutionary survival. Disbanding our own
            internal percetual biases first leaves us with even more mysteries.
            However, a major thrust of this scene analysis paper is that we
            really should acknowledge these mysteries and more closely examine
            mechanisms of animal perception to inform our research hypotheses.
            Doing so puts direct scientific observation in the driver&rsquo;s
            seat, and gives us a more unbiased view into the functioning of our
            minds.
          </p>
          <div class="footnotes" role="doc-endnotes">
            <hr />
            <ol>
              <li id="fn:1">
                <p>
                  Star Trek (TNG) not-so-famously introduced a character
                  &ldquo;Barclay&rdquo; who was obsessed with spending time in
                  the holodeck—a ship system that could create rich virtual
                  environments. The character name might be a subtle nod to
                  Berkeley or just a coincidence.&#160;<a
                    href="#fnref:1"
                    class="footnote-backref"
                    role="doc-backlink"
                    >&#x21a9;&#xfe0e;</a
                  >
                </p>
              </li>
              <li id="fn:2">
                <p>
                  Lewicki MS, Olshausen BA, Surlykke AS, and Moss CF. (2014)
                  Scene analysis in the natural environment.
                  <em>Frontiers in Psychology</em> 199 doi:<a
                    href="https://doi.org/10.3389/fpsyg.2014.00199"
                    target="_blank"
                    rel="noopener noreferrer"
                    >10.3389/fpsycg.2014.00199</a
                  >&#160;<a
                    href="#fnref:2"
                    class="footnote-backref"
                    role="doc-backlink"
                    >&#x21a9;&#xfe0e;</a
                  >
                </p>
              </li>
              <li id="fn:3">
                <p>
                  Granted, it <em>has</em> been a bit over 10 years since this
                  paper was published&hellip; &#x1f602;&#160;<a
                    href="#fnref:3"
                    class="footnote-backref"
                    role="doc-backlink"
                    >&#x21a9;&#xfe0e;</a
                  >
                </p>
              </li>
              <li id="fn:4">
                <p>
                  There is an epistemological theory based on this idea of
                  direct access to reality called direct realism:
                  <a
                    href="https://en.wikipedia.org/wiki/Direct_and_indirect_realism"
                    target="_blank"
                    rel="noopener noreferrer"
                    >https://en.wikipedia.org/wiki/Direct_and_indirect_realism</a
                  >&#160;<a
                    href="#fnref:4"
                    class="footnote-backref"
                    role="doc-backlink"
                    >&#x21a9;&#xfe0e;</a
                  >
                </p>
              </li>
              <li id="fn:5">
                <p>
                  I am reading
                  <a
                    href="https://www.amazon.com/Neuron-Brain-Robert-Martin/dp/1605354392"
                    target="_blank"
                    rel="noopener noreferrer"
                    >Neuron to Brain</a
                  >
                  and the introductory chapters outline how the limits of
                  physical chemistry drive to work as locally as possible, where
                  molecular proceses can occur much more efficiently than
                  generating expensive electrical pulse trains—especially over
                  longer distances.&#160;<a
                    href="#fnref:5"
                    class="footnote-backref"
                    role="doc-backlink"
                    >&#x21a9;&#xfe0e;</a
                  >
                </p>
              </li>
              <li id="fn:6">
                <p>
                  Saccades also compensate for our eyes being a kind of high
                  pass filter, suppressing visual signals that aren&rsquo;t
                  moving.&#160;<a
                    href="#fnref:6"
                    class="footnote-backref"
                    role="doc-backlink"
                    >&#x21a9;&#xfe0e;</a
                  >
                </p>
              </li>
              <li id="fn:7">
                <p>
                  This is really just one of many papers: Field D. J. (1987).
                  Relations between the statistics of natural images and the
                  response properties of cortical cells.
                  <em>J Opt Soc Am A., Optics and image science</em>, 4(12),
                  2379–2394. doi:<a
                    href="https://doi.org/10.1364/josaa.4.002379"
                    target="_blank"
                    rel="noopener noreferrer"
                    >10.1364/josaa.4.002379</a
                  >&#160;<a
                    href="#fnref:7"
                    class="footnote-backref"
                    role="doc-backlink"
                    >&#x21a9;&#xfe0e;</a
                  >
                </p>
              </li>
              <li id="fn:8">
                <p>
                  There is a really intersting paper<sup id="fnref:10"
                    ><a href="#fn:10" class="footnote-ref" role="doc-noteref"
                      >10</a
                    ></sup
                  >
                  that attempts to do this with a pretty famous Google-developed
                  neural network that broke Internet CAPTCHAs that I am probably
                  going to write about soon.&#160;<a
                    href="#fnref:8"
                    class="footnote-backref"
                    role="doc-backlink"
                    >&#x21a9;&#xfe0e;</a
                  >
                </p>
              </li>
              <li id="fn:9">
                <p>
                  See Footnote 1.&#160;<a
                    href="#fnref:9"
                    class="footnote-backref"
                    role="doc-backlink"
                    >&#x21a9;&#xfe0e;</a
                  >
                </p>
              </li>
              <li id="fn:10">
                <p>
                  George D, Lázaro-Gredilla M, Lehrach W, Dedieu A, Zhou G, and
                  Marino J. (2025) A detailed theory of thalamic and cortical
                  microcircuits for predictive visual inference.
                  <em>Sci. Adv.</em> 11, eadr6698. doi:<a
                    href="https://doi.org/10.1126/sciadv.adr6698"
                    target="_blank"
                    rel="noopener noreferrer"
                    >10.1126/sciadv.adr6698</a
                  >&#160;<a
                    href="#fnref:10"
                    class="footnote-backref"
                    role="doc-backlink"
                    >&#x21a9;&#xfe0e;</a
                  >
                </p>
              </li>
            </ol>
          </div>
        </div>
      </section>
    </main>
    <footer>
      <p>© Steven Hay 2025. All rights reserved.</p>
    </footer>
  </body>
</html>

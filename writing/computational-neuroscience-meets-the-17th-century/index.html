<!doctype html>
<html lang="en-us" dir="ltr">
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width" />
    <meta
      name="description"
      content="Do we live in a world of ideas? &#x1f4a1;"
    />
    <meta name="robots" content="index, follow" />
    <meta name="author" content="Steven Hay" />

    <link rel="canonical" href="" />

    <meta
      http-equiv="Content-Security-Policy"
      content="default-src 'self'; script-src 'self' https://stvhay.github.io;"
    />
    <meta name="referrer" content="strict-origin-when-cross-origin" />
    <meta
      http-equiv="Content-Security-Policy"
      content="frame-ancestors 'none';"
    />
    <meta http-equiv="X-Content-Type-Options" content="nosniff" />

    <title>
      Computational Neuroscience Meets the 17th Century | Steven Hay
    </title>
    <link
      rel="stylesheet"
      href="/css/main.min.d0f542d941fb79cb269a7b23a65e5cc4ed2af8a9ae742d657567c0f6ddc16b56.css"
      integrity="sha256-0PVC2UH7ecsmmnsjpl5cxO0q&#43;KmudC1ldWfA9t3Ba1Y="
      crossorigin="anonymous"
    />
  </head>
  <body>
    <header>
      <h1>Steven Hay</h1>
    </header>
    <nav>
      <a href="/">Home</a>
      <a href="/docs/cv/cv-steve-hay.pdf" target="_blank">CV</a>
      <a href="/portfolio/">Portfolio</a>
      <a href="/writing">Writing</a>
      <a href="/#contact">Contact</a>
    </nav>
    <main>
      <section class="container">
        <div class="article">
          <h1>Computational Neuroscience Meets the 17th Century</h1>
          <time datetime="2025-05-27T15:48:07-04:00">May 27, 2025</time>

          <br />
          <div class="article-img">
            <img
              src="/writing/computational-neuroscience-meets-the-17th-century/img.jpg"
              alt="Computational Neuroscience Meets the 17th Century"
            />
          </div>

          <p><em>Do we live in a world of ideas?</em> &#x1f4a1;</p>
          <p>
            Descartes famously kicked off an era of Western philosophy with his
            famous statement &ldquo;Cogito, ergo sum&rdquo; (I think, therefore
            I am). He went on to develop a dualistic theory of mind and body.
            The theory posits that the world is composed of fundamentally two
            types of &lsquo;stuff&rsquo;: stuff that extends into the
            three-dimensional space (matter) and suff that doesnt (ideas). For a
            long time this idea was popular, but in modern circles of
            philosophy, it has largely gone out of fashion in favor of
            materialism, which seems more sensible nowadays where technology and
            science so fundamentally shape our worldview.
          </p>
          <p>
            In the 17th century, things weren&rsquo;t quite as settled. Irish
            philosopher George Berkeley believed the opposite of materialism—the
            world (including all matter) was composed only of ideas
            <sup id="fnref:1"
              ><a href="#fn:1" class="footnote-ref" role="doc-noteref"
                >1</a
              ></sup
            >. Like materialists, he didn&rsquo;t really understand how dualism
            could make much sense (how does spirit interact with matter
            exactly?). My question is:
            <strong
              >does idealism offer us any relevant perspective when we study
              neuroscience</strong
            >?
          </p>
          <p>
            A 2014 paper<sup id="fnref:2"
              ><a href="#fn:2" class="footnote-ref" role="doc-noteref"
                >2</a
              ></sup
            >
            summarized the current state of neuroscience research on scene
            analysis—the study of how our brain turns converts sense-data into
            an internal representation of the world we see around us. It then
            argued that scene analysis is not only an incredibly hard problem,
            but that many of the ways we study this problem fail to address very
            fundamental and obvious questions.
          </p>
          <p>
            It turns out that most empirical research into scene analysis is
            conducted using very simplified forms—lines and basic geometric
            figures on simple backgrounds and neutral lighting. Arguably, this
            makes sense because it provides a controlled experimental
            environment. Unfortunately, while this research framework has given
            us many useful insights, we remain relatively stuck on how we map
            those insights to ecologically relevant scene analysis problems that
            all animals are constantly solving.<sup id="fnref:3"
              ><a href="#fn:3" class="footnote-ref" role="doc-noteref"
                >3</a
              ></sup
            >
          </p>
          <p>
            As I was reading, I was thinking about Berkeley&rsquo;s idealism. As
            I learn more about human perception, the more I realize that our
            perceptual world is far more like a Star Trek holodeck—<em
              >a constructed reality</em
            >—than an objective and independent interpretation of sense-data.
            Our lived experience is deeply subjective. Not only is our brain is
            deeply involved at every point in sensory processing, it constructs
            a model of the world from a surprisingly tiny subset of the
            information one might think is available. So, while I don&rsquo;t
            think the world is <em>literally</em> built of ideas, it is not a
            totally unreasonable way to approach how we study perception.
          </p>
          <p>
            As an example, saccades are rapid eye movements that constantly
            shift our gaze. The movements are essential for our ability to
            process visual information because we physically don&rsquo;t have
            the bandwidth to take in all of our visual field in without some
            form of multiplexing<sup id="fnref:4"
              ><a href="#fn:4" class="footnote-ref" role="doc-noteref"
                >4</a
              ></sup
            >. Our brain controls where our eyes are pointed based on a mix of
            unconscious neural control systems tracking our head, body, and eye
            position; random saccade and even smaller microsaccade movements, as
            well as high-level task-driven signals that determine our attention.
            All of the high-acuity visual data we get (e.g. detail and color)
            comes via a surprisingly narrow field of view, and the rest we fill
            in with prior knowledge and expectations and much more limited
            peripheral visual data.
          </p>
          <p>
            This motif recurs throughout the perceptive systems of most animals.
            For example, the paper discusses jumping spiders that have three
            pairs of different kinds of eyes—only one of the pairs providing
            detail, and provides it as a one-dimensional vertical slit. The
            spider uses these eyes to scan selected areas of its visual field
            horizontally like a crazed dot-matrix
            <a
              href="https://youtu.be/A_vXA058EDY?t=23"
              target="_blank"
              rel="noopener noreferrer"
              >printer</a
            >. Like us, the spider then assembles these samples into a
            three-dimensional representation of the world—the only way to
            explain its complex behaviors.
          </p>
          <p>
            Bats have even more impressive autonomic systems in place to operate
            their neural sonar. Not only do they generate (encode) and process
            (decode) various sophisticated sonar signals, they focus sonic
            energy at targets of interest, and also actively adjust their sonar
            transmission frequencies away from those of nearby bats to reduce
            interference.
          </p>
          <p>
            Meanwhile, some of our most famous computational models of vision
            bear little resemblance to these attention-driven biological
            systems. Consider the incredibly successful ResNet image classifier.
            It reads entire images, breaks them down into spatio-temporal
            chunks, then pieces it all back together into increasingly complex
            groups of pixels for grouping and labeling. While there is evidence
            for biological neurons doing spatio-temporal filtering<sup
              id="fnref:5"
              ><a href="#fn:5" class="footnote-ref" role="doc-noteref"
                >5</a
              ></sup
            >, Resnet has no concept of three-dimensional space other than what
            it has memorized, no opinions on what it should be paying attention
            to, and its overall computational structure doesn&rsquo;t have
            obvious traceability back to any biological systems. The success of
            ResNet has much more to do with its accomplishments as a technology
            than how it can explain the function of biological neural systems or
            animal behavior<sup id="fnref:6"
              ><a href="#fn:6" class="footnote-ref" role="doc-noteref"
                >6</a
              ></sup
            >.
          </p>
          <p>
            Yet we have the urge to apply ResNet to our search to understand the
            biological brain because of its impressive performance and because
            it resonates with our lived experience of perception. The human
            vision system makes us feel very connected to the world. It feels
            like our eyes are like cameras taking pictures or video. Therefore,
            it seems like the mind might process images like ResNet. The
            unconscious mechanisms of eye movement could seem like boring
            biological engineering details—a distraction from the really
            interesting stuff that makes up human perception and thought.
          </p>
          <p>
            So while we are not literally living in Berkeleyan world of ideas,
            the vast bulk of our perceptive reality can be viewed as a
            Berkeleyan mental construct. Our brain has made ourselves a
            holodeck<sup id="fnref:7"
              ><a href="#fn:7" class="footnote-ref" role="doc-noteref"
                >7</a
              ></sup
            >. Disbanding our own internal percetual biases first leaves us with
            even more mysteries. However, a major thrust of this scene analysis
            paper is that we really should accept that and more closely examine
            mechanisms of animal perception to inform our hypotheses. Doing so
            puts direct scientific observation in the driver&rsquo;s seat, and
            gives us a more unbiased view into the functioning of our minds.
          </p>
          <div class="footnotes" role="doc-endnotes">
            <hr />
            <ol>
              <li id="fn:1">
                <p>
                  Star Trek (TNG) not-so-famously introduced a character
                  &ldquo;Barclay&rdquo; who was obsessed with spending time in
                  the holodeck—a ship system that could create rich virtual
                  environments. The character name might be a subtle nod to
                  Berkeley or just a coincidence.&#160;<a
                    href="#fnref:1"
                    class="footnote-backref"
                    role="doc-backlink"
                    >&#x21a9;&#xfe0e;</a
                  >
                </p>
              </li>
              <li id="fn:2">
                <p>
                  Lewicki MS, Olshausen BA, Surlykke AS, and Moss CF. (2014)
                  Scene analysis in the natural environment.
                  <em>Frontiers in Psychology</em> 199 doi:<a
                    href="https://doi.org/10.3389/fpsyg.2014.00199"
                    target="_blank"
                    rel="noopener noreferrer"
                    >10.3389/fpsycg.2014.00199</a
                  >&#160;<a
                    href="#fnref:2"
                    class="footnote-backref"
                    role="doc-backlink"
                    >&#x21a9;&#xfe0e;</a
                  >
                </p>
              </li>
              <li id="fn:3">
                <p>
                  Granted, it <em>has</em> been a bit over 10 years since this
                  paper was published&hellip; &#x1f602;&#160;<a
                    href="#fnref:3"
                    class="footnote-backref"
                    role="doc-backlink"
                    >&#x21a9;&#xfe0e;</a
                  >
                </p>
              </li>
              <li id="fn:4">
                <p>
                  Saccades also compensate for our eyes being a kind of high
                  pass filter, suppressing visual signals that aren&rsquo;t
                  moving.&#160;<a
                    href="#fnref:4"
                    class="footnote-backref"
                    role="doc-backlink"
                    >&#x21a9;&#xfe0e;</a
                  >
                </p>
              </li>
              <li id="fn:5">
                <p>
                  This is really just one of many papers: Field D. J. (1987).
                  Relations between the statistics of natural images and the
                  response properties of cortical cells.
                  <em>J Opt Soc Am A., Optics and image science</em>, 4(12),
                  2379–2394. doi:<a
                    href="https://doi.org/10.1364/josaa.4.002379"
                    target="_blank"
                    rel="noopener noreferrer"
                    >10.1364/josaa.4.002379</a
                  >&#160;<a
                    href="#fnref:5"
                    class="footnote-backref"
                    role="doc-backlink"
                    >&#x21a9;&#xfe0e;</a
                  >
                </p>
              </li>
              <li id="fn:6">
                <p>
                  There is a really intersting paper<sup id="fnref:8"
                    ><a href="#fn:8" class="footnote-ref" role="doc-noteref"
                      >8</a
                    ></sup
                  >
                  that attempts to do this with a pretty famous Google-developed
                  neural network that broke Internet CAPTCHAs that I am probably
                  going to write about soon.&#160;<a
                    href="#fnref:6"
                    class="footnote-backref"
                    role="doc-backlink"
                    >&#x21a9;&#xfe0e;</a
                  >
                </p>
              </li>
              <li id="fn:7">
                <p>
                  See Footnote 1.&#160;<a
                    href="#fnref:7"
                    class="footnote-backref"
                    role="doc-backlink"
                    >&#x21a9;&#xfe0e;</a
                  >
                </p>
              </li>
              <li id="fn:8">
                <p>
                  George D, Lázaro-Gredilla M, Lehrach W, Dedieu A, Zhou G, and
                  Marino J. (2025) A detailed theory of thalamic and cortical
                  microcircuits for predictive visual inference.
                  <em>Sci. Adv.</em> 11, eadr6698. doi:<a
                    href="https://doi.org/10.1126/sciadv.adr6698"
                    target="_blank"
                    rel="noopener noreferrer"
                    >10.1126/sciadv.adr6698</a
                  >&#160;<a
                    href="#fnref:8"
                    class="footnote-backref"
                    role="doc-backlink"
                    >&#x21a9;&#xfe0e;</a
                  >
                </p>
              </li>
            </ol>
          </div>
        </div>
      </section>
    </main>
    <footer>
      <p>© Steven Hay 2025. All rights reserved.</p>
    </footer>
  </body>
</html>
